{"meta":{"title":"凡所有相，皆是虚妄。若见诸相非相，即见如来","subtitle":null,"description":null,"author":"影风","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"Shell编程基础","slug":"Shell编程基础","date":"2018-05-18T07:44:44.000Z","updated":"2019-05-17T07:59:31.916Z","comments":false,"path":"2018/05/18/Shell编程基础/","link":"","permalink":"http://yoursite.com/2018/05/18/Shell编程基础/","excerpt":"","text":"变量替换 ${变量名#匹配规则}：从变量开头进行规则匹配，将符合最短的数据删除 ${变量名##匹配规则}：从变量开头进行规则匹配，将符合最长的数据删除 ${变量名%匹配规则}：从变量尾部进行规则匹配，将符合最短的数据删除 ${变量名%%匹配规则}：从变量尾部进行规则匹配，将符合最长的数据删除 ${变量名/旧字符串/新字符串}：变量内容符合旧字符串则，则第一个旧字符串会被新字符串取代 ${变量名//旧字符串/新字符串}：变量内容符合旧字符串则，则全部的旧字符串会被新字符串取代1234567891011121314#!/bin/bashmessage=\"I love you, Do you love me\"a1=$&#123;message#*ov&#125;a2=$&#123;message##*ov&#125;a3=$&#123;message%ov*&#125;a4=$&#123;message%%ov*&#125;a5=$&#123;message/ov/OV&#125;a6=$&#123;message//ov/OV&#125;echo \"a1:$&#123;a1&#125;\"echo \"a2:$&#123;a2&#125;\"#echo \"a3:$&#123;a3&#125;\"echo \"a4:$&#123;a4&#125;\"echo \"a5:$&#123;a5&#125;\"echo \"a6:$&#123;a6&#125;\" 变量测试与内容替换 计算字符串的长度 “${ #string }” expr length “$string” （string有空格，则必须加双引号） 获取子串在字符串中的索引位置 expr index $string $substring 计算子串长度 expr match $string substr 抽取子串 ${string:position}：从string中的position开始 ${string:position:length}：从position开始，匹配长度为length ${string:-position}：从右边开始匹配 ${string:(position)}：从左边开始匹配 expr substr $string $position $length：从position开始，匹配长度为length 综合实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#!/usr/bin/env bashstring=\"Bigdata process framework is Hadoop,Hadoop is an open source project\"function tips_info&#123; echo \"******************************************\" echo \"*** (1) 打印字符串长度\" echo \"*** (2) 在整个字符串中删除Hadoop\" echo \"*** (3) 替换第一个Hadoop为Mapreduce\" echo \"*** (4) 替换全部Hadoop为Mapreduce\" echo \"******************************************\"&#125;function print_len&#123; if [ -z \"$string\" ]; then echo \"错误，字符串为空\" exit 1 else echo \"$&#123;#string&#125;\" fi&#125;function del_hadoop&#123; if [ -z \"$string\" ]; then echo \"错误，字符串为空\" exit 1 else echo \"$&#123;string//Hadoop/&#125;\" fi&#125;function rep_hadoop_mapreduce_first&#123; if [ -z \"$string\" ]; then echo \"错误，字符串为空\" exit 1 else echo \"$&#123;string/Hadoop/Mapreduce&#125;\" fi&#125;function rep_hadoop_mapreduce_all&#123; if [ -z \"$string\" ]; then echo \"错误，字符串为空\" exit 1 else echo \"$&#123;string//Hadoop/Mapreduce&#125;\" fi&#125;while truedoecho \"【字符串内容为\\\"$string\\\"】\"tips_inforead -p \"请输入您需要操作的编号【1，2，3，4，q|Q】\" choicecase \"$choice\" in 1) echo echo \"字符串的长度为: `print_len`\" echo continue ;; 2) echo echo \"删除Hadoop后的字符串为：`del_hadoop`\" echo ;; 3) echo echo \"替换第一个Hadoop的字符串为：`rep_hadoop_mapreduce_first`\" echo ;; 4) echo echo \"替换第一个Hadoop的字符串为：`rep_hadoop_mapreduce_all`\" echo ;; q|Q) exit 0 ;; *) echo \"输入错误请重新输入\" continue ;;esacdone 命令替换 `command` $(command) 和$()两者是等价的，需要注意的是$(())主要用来进行证书运算，包括加减乘除，引用变量前面可以加$，也可以不加$ 12345678910111213141516171819202122232425#### Example1:列出所有系统用户#!/bin/bashindex=1for user in `cat /etc/passwd | cut -d \":\" -f 1`do echo \"This is $index user: $user\" index=$(($index + 1))done#### 年份计算#!/bin/bashecho \"This year have passed $(date +%j) days\"echo \"This year have passed $(($(date +%j)/7)) weeks\"echo \"There is $((365 - $(date +%j))) days before new year\"echo \"There is $(((365 - $(date +%j))/7)) weeks before new year\"#### 启动nginx#!/bin/bashnginx_process_num=$(ps -ef | grep nginx | grep -v grep | wc -l)if [ $nginx_process_num -eq 0 ];then systemctl start nginxfi declare 和 typeset命令 两者等价 都是用来定义变量类型 参数 含义 -r 将变量设为只读 -i 将变量设为整数 -a 将变量定义为数组 -f 显示此脚本前定义过的所有函数及内容 -F 仅显示此脚本前定义过的函数名 -x 将变量声明为环境变量 1234567891011121314151617181920212223242526272829303132333435##定义数组decalre -a##给数组赋值array=(\"yang\" \"zhang\" \"zhou\" \"ding\" \"yuan\")##输出数组全部内容echo $&#123;array[@]&#125;##输出数组下标为1的元素echo $&#123;array[1]&#125;##获取数组长度echo $&#123;#array&#125;##输出数组下标为1的元素的长度echo $&#123;#array[1]&#125;##清空数组unset array##清空数组元素unset array[1]##显示数组索引从1开始从3结束的元素echo $&#123;array[@]:1:3&#125;##将数组汇中所有元素中的a字母替换成Aecho $&#123;array[@]/a/A&#125;##数组遍列for v in $&#123;array[@]&#125;do echo $vdone 数学运算 expr $num1 operator $num2 $(($num1 operator $num2)) 操作符 含义 num1 \\ num2 num1不为空且非0，返回num1，否则返回num2 num1 &amp; num2 num1不为空且非0，返回num1，否则返回0 num1 &lt; num2 num1小于num2，返回1，否则返回0 num1 &lt;= num2 num1小于等于num2，返回1，否则返回0 num1 = num2 num1等于num2，返回1，否则返回0 num1 != num2 num1不等于num2，返回1，否则返回0 num1 &gt; num2 num1大于num2，返回1，否则返回0 num1 &gt;= num2 num1大于等于num2，返回1，否则返回0 num1 + num2 求和 num1 - num2 求差 num1 * num2 求积 num1 / num2 求商 num1 % num2 求余 123456789101112131415161718192021222324#!/bin/bashwhile truedo read -p \"请输入一个正整数: \" num expr $num + 1 &amp;&gt; /dev/null if [ $? -eq 0 ];then if [ `expr $num \\&gt; 0` -eq 1 ];then for((i=1;i&lt;=$num;i++)) do sum=`expr $sum + $i` done echo \"1+2+3+....+$num = $sum\" exit fi fi echo \"输入错误\" continuedone####补充 $?:获取函数返回值或者上一个命令的退出状态 bc 运算器，主要支持浮点数运算 变量scale可以设置保留位数，默认为0 echo “scale=4;30.5/3.3” | bc 函数 定义 123name() &#123;&#125;function name() &#123;&#125; 调用 直接函数名调用 函数内部可以直接使用$1、$2、、、$n 调用有参函数 func_name $1 $2 返回值 return 只能返回1-255的整数 通常只是用来供其他地方调用获取状态，通常仅返回0或1；0表示成功，1表示失败 echo 可以返回任何字符串结果 通常用于返回数据，比如一个字符串值或者列表值 全局变量 不做特殊声明，shell中的变量都是全局变量 大型脚本程序中函数中慎用全局变量 局部变量 定义变量时，使用local关键字 函数内外存在同名变量，则函数内部变量覆盖外部变量 函数库 经常使用的重复代码封装成函数文件 一般不直接执行，而是由其他脚本调用 库文件名的后缀建议使用.lib 库文件通常没有可执行选项 库文件无需和脚本在同级目录，只需在脚本中引用时指定 第一行一般使用#!/bin/echo，输出警告信息，避免用户执行 1234567891011121314151617181920212223## 带参数的函数调用例子#!/bin/bashfunction calcu&#123; case $2 in +) echo \"`expr $1 + $3`\" ;; -) echo \"`expr $1 - $3`\" ;; \\*) echo \"`expr $1 \\* $3`\" ;; /) echo \"`expr $1 / $3`\" ;; esac&#125;calcu $1 $2 $3 1234567891011121314151617## echo返回值例子#!/bin/bashfunction get_users&#123; users=`cat /etc/passwd | cut -d: -f1` echo $users&#125;user_list=`get_users`index=1for u in $user_listdo echo \"The $index user is : $u\" index=$(($index+1))done find命令 find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path…] [expression] 基本命令选项-H、-L、和-P控制着对符号链接的处理方式； 如果没有给定搜索路径[path…]，则默认为当前目录； 如果没有给定表达式[expression]，则默认为-print，将匹配的文件输出到标准输出。 -name：根据文件名查找 -perm：根据文件权限查找 -prune：通常和-path一起使用，用于将特定的目录排除在搜索条件之外 -user：根据文件属主查找 -group：根据文件属组查找 -mtime -n | +n：根据文件更改时间查找 -n表示文件更改时间距现在n天以内，+n表示文件更改时间距现在n天以前 -nogroup：查找无有效属组的文件 -nouser：查找无有效属主的文件 -newer file1 ! file2：查找更改时间比file1新但比file2旧的文件 -type：按文件类型查找 f：文件 d：目录 c：字符设备文件 b：块设备文件 l：链接文件 p：管道文件 -size -n +n：按文件大小查找 +n表示大于，-n表示小于 -mindepth n：从n级子目录开始搜索 -maxdepth n：最多搜索到n级子目录 1234567891011121314151617181920212223242526#查找文件名以docker前缀的所有文件find /usr/local/app -name 'docker*'#查找权限为777的文件find /etc -perm 777#在home目录下查找出除test目录及其子目录之外的所有文件find . -path \"./test\" -prune -o -print#查找文件属主是root的所有文件find . -user root#查找文件属属组是root的所有文件find . -group root#查找/etc目录下最近20天内更新的所有文件find /etc -mtime -20#查找home目录下所有的目录find . -type d#查找home目录下所有大于10M的文件find . -size +10M#查找无效属主的文件find / -nouser find、locate、whereis、which locate 文件查找命令，需要安装软件包 locate命令在数据库文件中查找 locate默认模糊匹配 可以使用updatedb命令立即更新数据库文件 whereis -b：只返回二进制文件 -m：只返回帮助文件 -s：只返回源代码文件 which -b：只返回二进制文件 命令 使用场景 优缺点 find 查找某一类文件，比如文件名部分一致 功能强大，速度慢 locate 只能查找单个文件 功能单一，速度快 whereis 查找程序的可执行文件、帮助文档等 不常用 which 只查找程序的可执行文件 常用于查找程序的绝对路径","categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}],"keywords":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}]},{"title":"文本处理三剑客","slug":"文本处理三剑客","date":"2018-05-17T07:42:54.000Z","updated":"2019-05-17T07:44:14.151Z","comments":false,"path":"2018/05/17/文本处理三剑客/","link":"","permalink":"http://yoursite.com/2018/05/17/文本处理三剑客/","excerpt":"","text":"grep：文本过滤工具grep [option] [pattern] [file1, file2] option -v：不显示匹配行信息 -i：搜索时忽略大小写 -n：显示行号 -r：递归搜索 -E：支持扩展正则表达式，相当于egrep命令 -F：不按正则表达式匹配,按照字符串字面意思匹配 12345678#输出要匹配的所有行grep root /etc/passwd#输出除要匹配的之外的所有行grep -v root /etc/passwd#递归搜索etc目录中所有文件grep -r -n root /etc sed：文本编辑工具stdout | sed [option] “pattern command”sed [option] “pattern command” file option -e：直接在命令行进行sed编辑，默认选项 -n：只打印模式匹配行 -f：编辑动作保存在文件中，指定文件执行 -r：支持扩展正则表达式 -i：直接修改文件内容 command 类别 编辑命令 含义 查询 p 打印 增加 a 行后追加 增加 i 行前追加 增加 r 外部文件读入，行后追加 增加 w 匹配行写入外部文件 删除 d 删除 修改 s/old/new 将行内第一个old替换为new 修改 s/old/new/g 将行内所有old替换为new 修改 s/old/new/2g 将行内前2个old替换为new 修改 s/old/new/ig 将行内所有old替换为new，且忽略大小写 1234567891011121314151617181920#输出文本第一行记录sed -n '1p' test.txt#将修改应用到文件中sed -i '1d' test.txt#输出所有匹配nologin的行sed -n '/nologin/p' test.txt#在所有匹配nologin的行后面追加|OKsed -i '/nologin/i |OK' test.txt#删除第一行至第五行数据sed -i '1,5d' test.txt#替换每一行所有nologin为oksed -i 's/nologin/ok/ig' test.txt#删除配置文件中的所有注释行和空行sed -i '/[:blank]*#/d' default.conf awk：文本报告生成器awk ‘BEGIN{} pattern {commands} END{}’ filenamestandard output awk ‘BEGIN{} pattern {commands} END{}’ 语法格式 BEGIN{}：正式处理数据之前执行 pattern：匹配模式 {commands}：处理命令，可能多行 END{}：处理完所有匹配数据后执行 内置变量 $0：整行内容 $1-$n：当前行的第1-n个字段 NF：当前行的字段个数，也就是有多少列 NR：当前行的行号，从1开始计数 FNR：多文件处理时，每个文件行号单独计数，都是从0开始 FS：输入字段分隔符，默认空格或tab键 RS：输入行分隔符，默认回车 OFS：输出字段分隔符，默认空格 ORS：输出行分隔符，默认回车 FILENAME：当前输入的文件名字 ARGC：命令行参数个数 ARGV：命令行参数数组1234567891011#文本内容Aaron|Abbott|Abel|Abner--Abraha|Adair|Adam|Addiso|Adolph#输出整行内容awk 'BEGIN&#123;FS=\"|\";RS=\"--\"&#125;&#123;print $0&#125;' test.log#输出每一行中的第2个字段awk 'BEGIN&#123;FS=\"|\";RS=\"--\"&#125;&#123;print $2&#125;' test.log#将输出的每一行用&amp;连接，每个字段用:连接awk 'BEGIN&#123;FS=\"|\";RS=\"--\";OFS=\":\";ORS=\"&amp;\"&#125;&#123;print $1,$2,$3&#125;' test.log 格式化输出 %s：占位符 %d：10进制数 %f：浮点数 %x：16进制数 %o：8进制数 %e：科学计数 %c：单个字符的ASCII码 -：左对齐 +：右对齐 #：8进制前面加0，16进制前面加0x 12345#使用占位符左对齐格式化输出awk 'BEGIN&#123;FS=\":\"&#125; &#123;printf \"%-20s %-20s\\n\", $1, $7&#125;' /etc/passwd#打印浮点数awk 'BEGIN&#123;FS=\":\"&#125; &#123;printf \"%0.2f\\n\", $3&#125;' /etc/passwd 匹配模式 正则匹配 关系运算匹配 &lt; > &lt;= >= == != 布尔运算符匹配 || &amp;&amp; ! 12345678#匹配以ssh开头的行awk 'BEGIN&#123;FS=\":\"&#125; /^ssh/ &#123;print $0&#125;' /etc/passwd#匹配第3个字段大于50的行awk 'BEGIN&#123;FS=\":\"&#125; $3 &gt; 50 &#123;print $0&#125;' /etc/passwd#匹配第3个字段大于10且小于50的行awk 'BEGIN&#123;FS=\":\"&#125; $3 &gt; 10 &amp;&amp; $3 &lt; 50 &#123;print $0&#125;' /etc/passwd 算数运算符 + - * / % ^或** ++x x++ 12#统计/etc/services中的空白行数awk '/^$/ &#123;sum++&#125; END&#123;print sum&#125;' /etc/services 字符串函数 length(str)：字符串长度 index(str1, str2)：在str1中查找str2的位置 tolower(str)：转换为小写 toupper(str)：转换为大写 substr(str, m, n)：从str的m个字符开始，截取m位 split(str, arr, fs)：按str切割字符串，结果保存arr match(str, regex)：在str中按照正则匹配，返回位置 sub(regex, reStr, str)：在str中搜索符合正则的字符串，将其替换成reStr，只替换1个 gsub(regex, reStr, str)：在str中搜索符合正则的字符串，将其替换成reStr，替换所有 12#统计/etc/passwd中每一行的第一个字段的长度awk 'BEGIN&#123;FS=\":\"&#125;&#123;print length($1)&#125;' /etc/passwd 数组 数组下标从1开始 可以使用字符串作为数据下标 1234567891011121314#数据遍历BEGIN &#123; arr[\"var1\"]=\"kobe\" arr[\"var2\"]=\"yaoming\" arr[\"var3\"]=\"wade\" arr[\"var4\"]=\"harden\" for (ar in arr) &#123; print arr[ar] &#125;&#125;#统计tcp连接数netstat -an | grep tcp | awk '&#123;array[$6]++&#125; END&#123; for(a in array) print a, array[a]&#125;' 选项 -v：参数传递 -f：指定脚本文件 -F：指定分隔符 -V：查看awk的版本号 1234567891011121314151617181920num1=1num2=2awk -v num1=\"$num1\" -v num2=\"$num2\" 'BEGIN&#123;print num1,num2&#125;'#文本内容Kobe 90 70 95 60Yaoming 88 90 60 90Howard 85 95 90 95McGrady 90 75 90 55#script.awkBEGIN &#123; printf \"%-15s%-10s%-10s%-10s%-10s%-10s\\n\", \"姓名\", \"进攻\", \"篮板\", \"弹跳\", \"防守\", \"综合\"&#125;&#123; total = $2 + $3 + $4 + $5 avg = total / 4 printf \"%-15s%-10d%-10d%-10d%-10d%-0.2f\\n\", $1, $2, $3, $4, $5, avg&#125; 条件语句 1234567if (表达式) &#123; 语句1&#125; else if (表达式) &#123; 语句2&#125; else &#123; 语句3&#125; 循环语句 12345678910111213141516#while循环BEGIN &#123; while (i &lt;= 100) &#123; total += i i++ &#125; print total&#125;#for循环BEGIN &#123; for(i=0; i&lt;=100; i++) &#123; total += i &#125; print total&#125; 12345678910111213141516171819202122232425262728293031321.根据访问IP统计UVawk &apos;&#123;print $1&#125;&apos; access.log | sort | uniq -c | wc -l2.统计访问URL统计PVawk &apos;&#123;print $7&#125;&apos; access.log | wc -l3.查询访问最频繁的URLawk &apos;&#123;print $7&#125;&apos; access.log | sort | uniq -c | sort -n -k 1 -r | more4.查询访问最频繁的IPawk &apos;&#123;print $1&#125;&apos; access.log | sort | uniq -c | sort -n -k 1 -r | more5.根据时间段统计查看日志cat access.log | sed -n &apos;/14\\/Mar\\/2015:21/, /14\\/Mar\\/2015:22/p&apos; | more6.统计IP访问个数（和根据访问IP统计UV一样）cat access.log | awk &apos;&#123;ips[$1]+=1&#125; END&#123;for(ip in ips) print ips[ip],ip&#125;&apos; | sort -nr | wc -l7.查看3点-6点之间的IP访问个数grep &quot;2016:0[3-6]&quot; access.log | awk &apos;&#123;ips[$1]+=1&#125; END&#123;for(ip in ips) print ips[ip],ip&#125;&apos; | sort –nr | wc -l8.查看3点-6点之间的ip访问数，并且访问数&gt;=200的ip.grep &apos;2016:0[3-12]&apos; access.log | awk &apos;&#123;ips[$1]+=1&#125;END&#123;for(ip in ips) if(ips[ip]&gt;=200) print ips[ip],ip&#125;&apos; | sort -nr9.查看并发连接数netstat -nat | grep ESTABLISHED | wc -l10.获取每分钟的请求数量，输出成csv文件cat access.log | awk &apos;&#123;print substr($4, 14, 5)&#125;&apos; | uniq -c | awk &apos;&#123;print $2&quot;, &quot;$1&#125;&apos; &gt; access.csv11.获取最耗时的请求时间、url、耗时，前10名, 可以修改后面的数字获取更多，不加则获取全部。cat /usr/local/nginx/logs/access.log | awk &apos;&#123;print $4,$7,$NF&#125;&apos; | awk -F &apos;&quot;&apos; &apos;&#123;print $1,$2,$3&#125;&apos; | sort -k3 -rn | head -10","categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://yoursite.com/tags/Shell/"}],"keywords":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}]},{"title":"CentOS搭建Redis集群","slug":"CentOS搭建Redis集群","date":"2018-04-28T16:58:48.000Z","updated":"2019-04-29T06:24:33.744Z","comments":false,"path":"2018/04/29/CentOS搭建Redis集群/","link":"","permalink":"http://yoursite.com/2018/04/29/CentOS搭建Redis集群/","excerpt":"","text":"下载源码并解压编译123456789yum -y install gcc automake autoconf libtool make rubymkdir -p /usr/local/rediscd /usr/local/rediswget http://download.redis.io/releases/redis-5.0.0.tar.gztar xzf redis-5.0.0.tar.gzcd redis-5.0.0make MALLOC=libc 创建Redis配置文件1234567891011121314151617181920mkdir -p /usr/local/redis/redis-cluster-conf/7001mkdir -p /usr/local/redis/redis-cluster-conf/7002mkdir -p /usr/local/redis/redis-cluster-conf/7003mkdir -p /usr/local/redis/redis-cluster-conf/7004mkdir -p /usr/local/redis/redis-cluster-conf/7005mkdir -p /usr/local/redis/redis-cluster-conf/7006vim redis.conf## 配置文件的内容为：## 其中 port 和 pidfile 需要随着 文件夹的不同调增。port 7001bind 192.168.6.223cluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000appendonly yesdaemonize yesprotected-mode nopidfile /var/run/redis_7001.pid 启动节点12345678/usr/local/redis/redis-5.0.0/src/redis-server /usr/local/redis/redis-cluster-conf/7001/redis.conf/usr/local/redis/redis-5.0.0/src/redis-server /usr/local/redis/redis-cluster-conf/7002/redis.conf/usr/local/redis/redis-5.0.0/src/redis-server /usr/local/redis/redis-cluster-conf/7003/redis.conf/usr/local/redis/redis-5.0.0/src/redis-server /usr/local/redis/redis-cluster-conf/7004/redis.conf/usr/local/redis/redis-5.0.0/src/redis-server /usr/local/redis/redis-cluster-conf/7005/redis.conf/usr/local/redis/redis-5.0.0/src/redis-server /usr/local/redis/redis-cluster-conf/7006/redis.conf## 按顺序执行，启动完之后通过ps -ef|grep redis命令查看启动的进程 启动集群1234## 3个master 3个slave/usr/local/redis/redis-5.0.0/src/redis-cli --cluster create 192.168.6.223:7001 192.168.6.223:7002 192.168.6.223:7003 192.168.6.223:7004 192.168.6.223:7005 192.168.6.223:7006 --cluster-replicas 1type yes 连接集群12345./redis-cli -h 192.168.6.223 -c -p 7001## 测试在7001上set a \"yjj\"在7003上get a 集群密码设置12345678## 每个节点都要设置config set masterauth abc123config set requirepass abc123auth abc123config rewrite## 带密码登录./redis-cli -h 192.168.6.223 -c -p 7001 -a abc123","categories":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}],"tags":[{"name":"集群","slug":"集群","permalink":"http://yoursite.com/tags/集群/"}],"keywords":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/categories/运维/"}]},{"title":"MySQL数据库常见优化","slug":"MySQL数据库常见优化","date":"2018-04-27T08:36:36.000Z","updated":"2019-05-07T02:22:22.712Z","comments":false,"path":"2018/04/27/MySQL数据库常见优化/","link":"","permalink":"http://yoursite.com/2018/04/27/MySQL数据库常见优化/","excerpt":"","text":"MySQL分区特点在逻辑上为一个表，在物理上存储在多个文件中 为什么要分区 分区可以在一个表中存储比单个磁盘或文件系统分区上的数据更多的数据，因为我们可以将分区表存储在不同物理磁盘上 对已过期或者不需要保存的数据，可以通过删除与这些数据有关的分区来快速删除数据，他的效率远比delete高 优化查询，在where子句中包含分区条件时，可以只扫描必要的一个或者多个分区来提高查询效率例：SELECT * FROM t PARTITION（p0，p1）WHERE c仅选择与WHERE条件匹配的分区p0和p1中的那些行在这种情况下，MySQL不检查表t的任何其他分区 涉及聚合函数SUM()、COUNT()的查询时，可以容易的在每个分区上并行处理例：SELECT salesperson_id，COUNT（orders）as order_total FROM sales GROUP BY salesperson_id会在每个分区上都同时运行查询 凭借在多个磁盘上传播数据，实现更高的查询吞吐量 缺点一个表最多只能有1024个分区，同一个分区表的所有分区必须使用相同存储引擎，分区表无法使用外键约束 3种常用分区类型HASH分区 根据MOD（分区键，分区数）的值把数据行存储到表的不同分区中 数据可以平均的分布在各个分区表中 HASH分区的键值必须是一个INT类型的值，或是通过函数可以转为INT类型12345678910111213141516171819202122CREATE TABLE `login_log` ( `id` int(10) unsigned NOT NULL, `login_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `login_ip` int(10) unsigned NOT NULL, `login_type` tinyint(4) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4PARTITION BY HASH (id)PARTITIONS 4CREATE TABLE `login_log` ( `id` int(10) unsigned NOT NULL, `login_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `login_ip` int(10) unsigned NOT NULL, `login_type` tinyint(4) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4PARTITION BY HASH (UNIX_TIMESTAMP(login_time))PARTITIONS 4USE information_schema;SELECT PARTITION_NAME,TABLE_ROWSFROM INFORMATION_SCHEMA.PARTITIONSWHERE TABLE_NAME = 'login_log'; RANGE分区 根据分区键值的范围把数据行存储到表的不同分区中 多个分区的范围要连续，但是不能重叠 默认情况下使用VALUES LESS THAN属性，即每个分区不包括指定的那个值 使用场景 分区键为日期或时间类型 所有查询中都包括分区键 定期按分区范围清理历史数据123456789101112CREATE TABLE `login_log` ( `id` int(10) unsigned NOT NULL, `login_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `login_ip` int(10) unsigned NOT NULL, `login_type` tinyint(4) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4PARTITION BY RANGE (id) ( PARTITION p0 VALUES LESS THAN (3), PARTITION p1 VALUES LESS THAN (6), PARTITION p2 VALUES LESS THAN (9), PARTITION p4 VALUES LESS THAN MAXVALUE) LIST分区 按分区键取值的列表进行分区 同范围分区一样，各分区的列表值不能重复 每一行数据必须能找到对应的分区列表，否则数据无法插入12345678910111213141516CREATE TABLE `login_log` ( `id` int(10) unsigned NOT NULL, `login_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, `login_ip` int(10) unsigned NOT NULL, `login_type` tinyint(4) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4PARTITION BY LIST (login_type) ( PARTITION p0 VALUES IN (1,2,3), PARTITION p1 VALUES IN (4,5,6))/*删除分区*/ALTER TABLE login_log DROP PARTITION p0/*迁移分区数据*/ALTER TABLE login_log EXCHAGE PARTITION p1 with TABLE arch_login_log 注意事项 结合业务场景选择分区方式，应避免跨分区查询 对分区表查询最好在WHERE从句中包含分区键 具有主键或唯一索引的表，主键或唯一索引必须是分区键的一部分 执行计划explain结果分析ID列 ID列表示SELECT语句的顺序 ID值相同时，执行顺序由上至下 ID值越大优先级越高，越先被执行 SELECT_TYPE列 SIMPLE：不包含子查询或UNION操作的查询 PRIMARY：查询中如果包含子查询，那么最外层的查询被标记为PRIMARY SUBQUERY：SEL ECT列表中的子查询 DEPENDENT SUBQUERY：依赖外部结果的子查询 UNION：UNION操作的第二个或是之后的查询的值为UNION DEPENDENT UNION：当UNION作为子查询时，第二或是第二个后的查询 UNION RESULT：UNION产生的结果集 DERIVED：出现在FROM子句中的子查询 TABLE列 输出数据行所在的表名称 PARTITIONS列 对于分区表，显示查询的分区ID 对于非分区表，显示为NULL TYPE列性能由高到低排列 system：const联接类型的一个特例当查询的表只有一行时使用 const：表中有且只有一个匹配的行时使用,如对主键或是唯一索引的查询最高的联接方式 eq_ref：唯一索或主键引查找,对于每个索引键,表中只有一条记录与之匹配 ref：非唯一索引查找,返回匹配某个单独值的所有行。 ref_or_null：类似于ref类型的查询,但是附加了对NULL值列的查询 index_merge：该联接类型表示使用了索引合并优化方法 range：索引范围扫描,常见于between, &gt;、&lt;这样的查询条件 index：全索引扫描,同ALL的区别是,遍历的是索引树 ALL：全表扫描,这是效率最差的联接方式 Extra列 Distinct：优化distinct操作,在找到第一匹配的元组后即停止找同样值的动作 Not exists：使用not exists来优化查询 Using filesort：使用额外操作进行排序，通常会出现在order by或group by查询 Using index：使用了覆盖索引进行查询 Using temporary：使用临时表来处理查询，常见于排序，子查询和分组查询 Using where：使用WHERE条件来过滤数据 select tables optimized away：直接通过索引来获得数据，不用访问表 POSSIBLE_KEYS列 指出MySQL能使用那些索引来优化查询 查询列所涉及到的列上的索引都会被列出,但不一定会被使用 KEY列 查询优化器优化查询实际所使用的索引 如果没有可用的索引，则显示为NULL 如查询使用了覆盖索引，则该索引仅出现在Key中 KEY_LEN列 表示索引字段的最大可能长度 KEY_LEN的长度由字段定义计算而来，并非数据的实际长度 Ref列 表示列或常量被用于查找索引列上的值 rows列 表示MySQL通过索引统计信息，估算的所需读取的行数 rows值的大小是个统计抽样结果，并不十分准确 Filtered列 表示返回结果的行数占需读取行数的百分比 Filtered列的值越大越好 Filtered列的值依赖统计信息 限制 无法展示存储过程、触发器、UDF对查询的影响 无法使用EXPLAIN对存储过程进行分析 早起版本的MySQL只支持SELECT语句 分页查询优化1234567891011select product_info.supplier_id, product_info.product_name, product_supplier_info.supplier_namefrom product_infoleft join product_supplier_infoon product_info.supplier_id = product_supplier_info.supplier_id limit 100, 500alter table product_info add index idx_supplier_id (supplier_id)/*增加联合索引达到覆盖索引效果*/alter table product_info add index idx_product_name_supplier_id (supplier_id, product_name)alter table product_supplier_info add index idx_supplier_name_supplier_id (supplier_id, supplier_name) 慢查询日志1234567891011121314/*查看是否开启了慢查询日志*/show variables like '%slow_query_log%'/*开启慢查询日志*/set global slow_query_log = on;/*未使用索引的查询也被记录到慢查询日志中*/set global log_queries_not_using_indexes = on;/*慢查询日志存储路径*/set global slow_query_log_file = '/var/lib/mysql/slow_query.log';/*当查询时间多于设定的阈值时，记录日志*/set global long_query_time = 0.001;/*shell 查看慢查询日志*/mysqldumpslow 3de27981f248-slow.log 123456789#!/bin/bashtime=`date -d yesterday + \"%Y-%m-%d\"`host=\"127.0.0.1\"user=\"root\"passwd=\"123456\"#提前创建好一个存放目录：/var/lib/mysql/slow_log/mv /var/lib/mysql/slow_query.log /var/lib/mysql/slow_log/slow_query_$time.logmysql -u$user -p$passwd -e \"set global slow_query_log_file='/var/lib/mysql/slow_query.log';\"### 每天0点执行该脚本","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}]},{"title":"MySQL数据库设计规范","slug":"MySQL数据库设计规范","date":"2018-04-26T08:36:36.000Z","updated":"2019-04-26T09:27:22.895Z","comments":false,"path":"2018/04/26/MySQL数据库设计规范/","link":"","permalink":"http://yoursite.com/2018/04/26/MySQL数据库设计规范/","excerpt":"","text":"数据库命名规范 所有数据库对象名称必须小写 命名要做到见名识意，禁止使用MySQL保留关键字 临时表以tmp_开头，备份表以bak_开头并以时间戳结尾 所有存储相同数据的列名和列类型必须一致 数据库基本设计规范 所有表必须使用Innodb存储引擎 支持事务，行级锁，更好的恢复性，高并发下性能更好 show engines; 数据库和表的字符集统一使用UTF-8 避免由于字符集转换产生乱码 汉字占3个字节，ASCII码占1个字节 所有表和字段必须添加注释 尽量控制单表数据量的大小，建议控制在500万行以内 可以用历史数据归档，分库分表等手段来控制数据量大小 谨慎使用MySQL分区表 分区表在物理上表现为多个文件，在逻辑上表现为一个表 跨分区查询效率会低 建议采用物理分表的方式管理大数据 尽量做到冷热数据分离，减小表宽度 减少磁盘I/O，保证热数据的内存缓存命中率 更有效的利用缓存，避免读入无用的冷数据 经常一起使用的列放到一个表中 禁止在表中建立预留字段 禁止在数据库中存储图片，文件等二进制数据 禁止在线上做数据库压力测试 禁止从开发环境、测试环境直连生产环境数据库 数据库索引设计规范 限制每张表上的索引数量，建议单张表索引不超过5个 禁止给表中的每一列都建立单独的索引 每张表都必须有一个主键 不使用更新频繁的列作为主键 不使用多列主键 不使用UUID，MD5，HASH，字符串作为主键 主键建议使用自增id值 WHERE从句、ORDER BY、GROUP BY、DISTINCT、多表JOIN中的列优先设置索引 设置索引列的顺序 区分度最高的列放在联合索引的最左侧 尽量把字段长度小的列放在联合索引的最左侧 使用最频繁的列放到联合索引的左侧 避免建立冗余索引和重复索引 primary key(id)、index(id)、unique index(id) index(a,b,c)、index(a,b)、index(a) 对于频繁的查询优先考虑使用覆盖索引 避免Innodb表进行索引的二次查找 可以把随机I/O变为顺序I/O加快查询效率 尽量避免使用外键 外键可用于保证数据的参照完整性，但建议在业务端实现 外键会影响父表和子表的写操作从而降低性能 数据库字段设计规范 优先选择符合存储需要的最小的数据类型 将字符串转化为数字类型存储，INET_ATON(‘255.255.255.255’)，INET_NTOA(4294967295) 对于非负整数应采用无符号整型进行存储 VARCHAR(N)中的N指定要明确，过大的长度会消耗更多的内存 避免使用TEXT、BLOB数据类型 建议把BLOB或者TEXT分离到单独的扩展表中 TEXT或BLOB类型只能使用前缀索引 避免使用ENUM数据类型 尽可能把所有列定义为NOT NULL 索引NULL列需要额外的空间来保存 进行比较和计算要对NULL值做特别的处理 不要用字符串存储日期类型的数据 无法用日期函数进行计算和比较 用字符串存储日期要占更多的空间 使用TIMESTAMP或DATETIME类型存储时间 TIMESTAMP占用4字节和INT相同，但比INT可读性高 超出TIMESTAMP取值范围的时候用DATETIME TIMESTAMP 1970～01～01 ～ 2038-01-19 财务相关的金额类数据，必须使用decimal类型 SQL开发规范 建议使用预编译语句进行数据库操作 避免数据类型的隐式转换 select phone from user where id = ‘1’ 充分利用表上已经存在的索引 避免使用双%号的查询条件 使用left join 或 not exists 优化not in操作 禁止跨库查询 禁止使用SELECT *，必须使用SELECT &lt;字段列表&gt; 查询 禁止使用不含字段列表的INSERT语句 避免使用子查询，可以把子查询优化为join操作 避免使用JOIN关联太多的表，建议不超过5个 合并多个相同操作到一起，减少同数据库交互次数 使用in代替or，in的值不要超过500，in操作可以利用索引 禁止使用order by rand() 进行随机排序 WHERE从句中禁止队列进行函数转换和计算 where date(time) = ‘20160901’ where createtime &gt;= ‘20160901’ and createtime &lt; ‘20160902’ 在明显不会有重复值时使用UNION ALL，而不是UNION 拆分复杂的大SQL为多个小SQL 一个SQL只能使用一个CPU进行计算 数据库操作规范 超过100万行的批量写操作，要分批多次进行操作 大批量操作可能会造成严重的主从延迟 binlog日志为ROW格式会产生大量的日志 避免产生大事务操作 对大表数据结构的修改要谨慎，会造成严重的锁表操作 使用pt-online-schema-change修改表结构 禁止为程序使用的账号赋予super权限 程序使用的账号原则上不准有drop权限","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/数据库/"}]}]}